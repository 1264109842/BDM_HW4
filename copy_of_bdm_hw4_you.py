# -*- coding: utf-8 -*-
"""Copy of BDM_HW4_You.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jGwVKQpU5SmQxANK3m2FUzgrcPdX99bV
"""

# !pip install pyspark

import pyspark
import json
import csv
from datetime import datetime
from datetime import timedelta  
from pyspark.sql import SparkSession
import numpy as np
from pyspark.sql import functions as F
from pyspark.sql.types import DateType, IntegerType, MapType, StringType, ArrayType
from pyspark.sql.functions import split, col, substring, regexp_replace, explode, broadcast, when

sc = pyspark.SparkContext()
spark = SparkSession(sc)

def mapday(s, v):
  date_1 = datetime.strptime(s[:10], '%Y-%m-%d')
  result = {}

  l = json.loads(v)

  for i in range(0,7):
    date = date_1 + timedelta(days=i)
    result[date] = l[i]

  return result

def median(values_list):
  med = np.median(values_list)
  stdev = np.std(values_list)
  low = int(med-stdev)
  high = int(med+stdev)

  result = []

  result.append(int(med))
  result.append(low) if low > 0 else result.append(0)
  result.append(high) if high > 0 else result.append(0)

  return result 

udfExpand = F.udf(mapday, MapType(DateType(), IntegerType()))
udfMedian = F.udf(median, ArrayType(IntegerType()))
  
if __name__=='__main__':

  NAICS = [['452210','452311'],['445120'],['722410'],
         ['722511'],['722513'],['446110','446191'],['311811','722515'],
         ['445210','445220','445230','445291','445292','445299'],['445110']]

  TNAICS = ['0','1','2','3','4','5','6','7','8']

  files = ["/big_box_grocers", "/convenience_stores", "/drinking_places",
          "/full_service_restaurants", "/limited_service_restaurants", "/pharmacies_and_drug_stores",
          "/snack_and_bakeries", "/specialty_food_stores", "/supermarkets_except_convenience_stores"]

  newdf = spark.read.csv('hdfs:///data/share/bdm/weekly-patterns-nyc-2019-2020/*', header=True)
  new = spark.read.csv('hdfs:///data/share/bdm/core-places-nyc.csv', header= True)

  # df = new.where(F.col('naics_code').isin(TNAICS))

  df = new.withColumn("key", when(F.col('naics_code').isin(NAICS[0]), '0')
                            .when(F.col('naics_code').isin(NAICS[1]), '1')
                            .when(F.col('naics_code').isin(NAICS[2]), '2')
                            .when(F.col('naics_code').isin(NAICS[3]), '3')
                            .when(F.col('naics_code').isin(NAICS[4]), '4')
                            .when(F.col('naics_code').isin(NAICS[5]), '5')
                            .when(F.col('naics_code').isin(NAICS[6]), '6')
                            .when(F.col('naics_code').isin(NAICS[7]), '7')
                            .when(F.col('naics_code').isin(NAICS[8]), '8')
                     )
  
  dff = df.where(F.col('key').isin(TNAICS))

  newDF = newdf.join(broadcast(dff), (newdf.placekey == dff.placekey) & (newdf.safegraph_place_id == dff.safegraph_place_id))\
                   .select(F.explode(udfExpand('date_range_start', 'visits_by_day')).alias('date', 'visits'), 'key')
  
  newDFF = newDF.where((newDF.date > '2018-12-31') & (newDF.date < '2021-01-01') & (newDF.visits > 0))\
                .groupBy('key', 'date')\
                .agg(F.collect_list('visits').alias('visits'))\
                .withColumn('median', udfMedian('visits'))\
                .withColumn('year', substring('date',1,4))\
                .withColumn('date', regexp_replace('date', '2019', '2020'))\
                .orderBy('year', 'date')

  for i in range(len(NAICS)):

      newDFF.where(F.col('key').isin(TNAICS[i]))\
            .select('year', 'date', newDFF.median[0].alias('median'),newDFF.median[1].alias('low'),newDFF.median[2].alias('high'))\
            .coalesce(1)\
            .write.format("csv")\
            .option("header","true")\
            .save('test'+files[i])

  # for i in range(len(NAICS)):
  #   df = new.where(F.col('naics_code').isin(NAICS[i]))

  #   newDF = newdf.join(broadcast(df), (newdf.placekey == df.placekey))\
  #                 .select(F.explode(udfExpand('date_range_start', 'visits_by_day')).alias('date', 'visits'))


  #   newDFF = newDF.where((newDF.date > '2018-12-31') & (newDF.date < '2021-01-01') & (newDF.visits > 0))\
  #                 .groupBy('date')\
  #                 .agg(F.collect_list('visits').alias('visits'))\
  #                 .withColumn('median', udfMedian('visits'))\
  #                 .withColumn('year', substring('date',1,4))\
  #                 .withColumn('date', regexp_replace('date', '2019', '2020'))\
  #                 .orderBy('year', 'date')

  #   newDFFF = newDFF.select('year', 'date', newDFF.median[0].alias('median'),newDFF.median[1].alias('low'),newDFF.median[2].alias('high'))\
  #                   .coalesce(1)\
  #                   .write.format("csv")\
  #                   .option("header","true")\
  #                   .save('test'+files[i])

newDFFF.show()